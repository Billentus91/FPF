# -*- coding: utf-8 -*-
"""FPF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z-GZOE7nwUtRzDL7PrZSbTGMPSoza4Nh
"""

import streamlit as st
import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import load_model
import joblib
import json

# ================================
# DATA LOADING FUNCTIONS (Separate as requested)
# ================================

def load_stock_data(ticker, period='6y'):
    """Load QQQ stock data from Yahoo Finance with error handling"""
    try:
        data = yf.download(ticker, period=period)
        if data.empty:
            raise ValueError(f"No data retrieved for {ticker}")
        if isinstance(data.columns, pd.MultiIndex):
            data.columns = data.columns.get_level_values(0)
        return data
    except Exception as e:
        st.error(f"Error loading data for {ticker}: {e}")
        return pd.DataFrame()

def load_stock_data2(ticker, period='5y'):
    """Load SPY stock data from Yahoo Finance with error handling"""
    try:
        data = yf.download(ticker, period=period)
        if data.empty:
            raise ValueError(f"No data retrieved for {ticker}")
        if isinstance(data.columns, pd.MultiIndex):
            data.columns = data.columns.get_level_values(0)
        return data
    except Exception as e:
        st.error(f"Error loading data for {ticker}: {e}")
        return pd.DataFrame()

# ================================
# DATA CLEANING AND PREPROCESSING FUNCTIONS
# ================================

def clean_stock_data(data, ticker_name):
    """Comprehensive data cleaning based on the original script"""
    df = data.copy()
    df = df[~df.index.duplicated(keep='last')]
    df = df.sort_index()
    core_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
    df[core_columns] = df[core_columns].ffill()
    df = df.dropna(subset=core_columns)
    price_cols = ['Open', 'High', 'Low', 'Close']
    df = df[(df[price_cols] > 0).all(axis=1)]
    df = df[df['High'] >= df['Low']]
    df['price_change'] = df['Close'].pct_change()
    df['price_change'] = df['price_change'].clip(-0.5, 0.5)
    if 'Volume' in df.columns:
        median_volume = df['Volume'][df['Volume'] > 0].median()
        df.loc[df['Volume'] <= 0, 'Volume'] = median_volume
    return df

def preprocess_data(data, ticker_name):
    """Preprocessing and feature calculation"""
    df = data.copy()
    df['returns'] = df['Close'].pct_change()
    df['volatility'] = df['returns'].rolling(window=5).std() * np.sqrt(5)
    df['sma_10'] = df['Close'].rolling(window=10).mean()
    df['sma_20'] = df['Close'].rolling(window=20).mean()
    df['price_ratio'] = df['Close'] / df['sma_20']
    df['volume_sma'] = df['Volume'].rolling(window=10).mean()
    df['volume_ratio'] = df['Volume'] / df['volume_sma']
    df['momentum_5'] = df['Close'] / df['Close'].shift(5)
    df['momentum_10'] = df['Close'] / df['Close'].shift(10)
    df['hl_ratio'] = (df['High'] - df['Low']) / df['Close']
    df['ticker'] = ticker_name
    df.columns.name = None
    return df

def create_features(df):
    """Create additional features for the model"""
    for lag in [1, 2, 3, 5]:
        df[f'volatility_lag_{lag}'] = df['volatility'].shift(lag)
    df['volatility_ma_5'] = df['volatility'].rolling(window=5).mean()
    df['volatility_ma_10'] = df['volatility'].rolling(window=10).mean()
    df['volatility_std_5'] = df['volatility'].rolling(window=5).std()
    for lag in [1, 2, 3]:
        df[f'returns_lag_{lag}'] = df['returns'].shift(lag)
    return df

def create_sequences(data, features, target, sequence_length=10):
    """Create sequences for LSTM input"""
    X, y = [], []
    for i in range(sequence_length, len(data)):
        X.append(data[features].iloc[i-sequence_length:i].values)
        y.append(data[target].iloc[i])
    return np.array(X), np.array(y)

# ================================
# STREAMLIT APP LAYOUT
# ================================

st.title("Tanabyt Volatility Forecast")
st.markdown("This dashboard predicts the 10-day rolling volatility for QQQ and SPY using two separate LSTM models trained on historical stock data.")

# Sidebar for user input
st.sidebar.header("Select a Stock")
ticker = st.sidebar.selectbox("Choose a stock to analyze:", ("QQQ", "SPY"))

# Load the required model and scalers based on user selection
@st.cache_resource
def load_assets(ticker_name):
    model_path = f'{ticker_name.lower()}_model.keras'
    feature_scaler_path = f'{ticker_name.lower()}_feature_scaler.pkl'
    target_scaler_path = f'{ticker_name.lower()}_target_scaler.pkl'

    try:
        model = load_model(model_path)
        feature_scaler = joblib.load(feature_scaler_path)
        target_scaler = joblib.load(target_scaler_path)
        return model, feature_scaler, target_scaler
    except FileNotFoundError:
        st.error(f"Required model or scaler files for {ticker_name} not found. Please ensure {model_path}, {feature_scaler_path}, and {target_scaler_path} are in the same directory.")
        return None, None, None

model, feature_scaler, target_scaler = load_assets(ticker)

if model and feature_scaler and target_scaler:
    st.subheader(f"Analyzing {ticker} Volatility")

    # Load and prepare data using the correct loading function
    if ticker == 'QQQ':
        data = load_stock_data(ticker)
    elif ticker == 'SPY':
        data = load_stock_data2(ticker)
    else:
        st.error("Invalid ticker selected.")
        data = pd.DataFrame()

    if not data.empty:
        # Preprocess and create features
        clean_raw = clean_stock_data(data, ticker)
        processed = preprocess_data(clean_raw, ticker)
        final_data = create_features(processed).dropna()

        # Define features and target as in the original script
        feature_columns = [
            'returns', 'price_ratio', 'volume_ratio', 'momentum_5', 'momentum_10',
            'hl_ratio', 'volatility_lag_1', 'volatility_lag_2', 'volatility_lag_3',
            'volatility_lag_5', 'volatility_ma_5', 'volatility_ma_10', 'volatility_std_5',
            'returns_lag_1', 'returns_lag_2', 'returns_lag_3'
        ]
        target_column = 'volatility'
        SEQUENCE_LENGTH = 10

        # Create sequences for prediction
        X, y = create_sequences(final_data, feature_columns, target_column, SEQUENCE_LENGTH)

        if len(X) > 0:
            # Scale the features
            X_scaled_reshaped = X.reshape(-1, X.shape[-1])
            X_scaled = feature_scaler.transform(X_scaled_reshaped).reshape(X.shape)

            # Make a prediction
            # Let's predict the last 10 points
            num_points_to_show = 10
            X_test_scaled_subset = X_scaled[-num_points_to_show:]
            y_test_subset = y[-num_points_to_show:]

            y_pred_scaled = model.predict(X_test_scaled_subset, verbose=0)
            y_pred = target_scaler.inverse_transform(y_pred_scaled).flatten()
            y_actual = y_test_subset

            # Create a DataFrame for plotting
            prediction_df = pd.DataFrame({
                'Date': final_data.index[-num_points_to_show:],
                'Actual Volatility': y_actual,
                'Predicted Volatility': y_pred
            })
            prediction_df = prediction_df.set_index('Date')

            # Display the graph
            st.markdown("### 10-Day Predicted vs. Actual Volatility")
            st.line_chart(prediction_df)

            st.write(prediction_df)

            # Display the model metrics
            st.markdown("### Model Evaluation Metrics")
            try:
                with open('model_metrics.json', 'r') as f:
                    metrics = json.load(f)

                stock_metrics = metrics[f'{ticker.lower()}_test']

                st.table(pd.DataFrame({
                    "Metric": ["Mean Squared Error (MSE)", "Root Mean Squared Error (RMSE)", "Mean Absolute Error (MAE)", "R-squared (RÂ²)"],
                    f"Value for {ticker}": [
                        f"{stock_metrics['mse']:.6f}",
                        f"{stock_metrics['rmse']:.6f}",
                        f"{stock_metrics['mae']:.6f}",
                        f"{stock_metrics['r2']:.4f}"
                    ]
                }).set_index("Metric"))

            except FileNotFoundError:
                st.warning("`model_metrics.json` not found. Please run the training script to generate it.")
        else:
            st.warning("Not enough data points to create sequences for prediction.")
